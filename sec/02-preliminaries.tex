\section{Preliminaries}

%\subsection{$k$-safety hyperproperties}


\subsection{Cartesian Hoare logic}

Introduced in~\cite{SousaD16}, Cartesian Hoare Logic is a formalism for
specifying and reasoning about k-safety properties, in a similar way as Hoare
logic is used to reason about (safety) properties. In Hoare logic, properties are
specified by means of so-called \emph{Hoare triples}.  These have the shape
$\{ \varphi \} S \{ \psi \}$, with the meaning that the formula $\psi$ holds
in any state after the termination (if any) of the program $S$, executed from
a state satisfying $\varphi$.  In Cartesian Hoare logic, the situation is
similar: one can specify a triple
$\langle \Phi \rangle\ S_1 \st \cdots \st S_k\ \langle \Psi \rangle$ with the
following meaning: for any $k$-tuple $(\sigma_1,\ldots,\sigma_k)$ of states
satisfying the formula $\Phi$, if we execute each program $S_i$ in the
respective state $\sigma_i$ and they all terminate, then the $k$-tuple
$(\sigma_1^\prime,\ldots,\sigma_k^\prime)$ of the resulting program states
satisfies $\Psi$ \footnote{An important technical assumption here is that
  every program $S_i$ operates on its own set of program variables, distinct
  from variables of other programs $S_j$ (for $i \not = j$) - otherwise, the
  formulas $\Phi$ and $\Psi$ would not be able to distinguish between program
  variables of different programs.}.
%To make specifications more compact, one can also consider triples $|| \Phi ||\ S \ || \Psi ||$ 

As an example, consider the program $P(x,y) \equiv \texttt{while(x > 0) \{ x--; y++; \} }$ and the 2-safety property
of \emph{monotonicity} stating, intuitively: with growing inputs $x$ and $y$, the resulting $y$ also grows.
In CHL, this can be formalized as
\begin{equation}\label{eq:mono_formula}
\langle x_1 \leq x_2 \land y_1 \leq y_2  \rangle\ P(x_1, y_1)\st{}P(x_2, y_2)\  \langle y_1 \leq y_2 \rangle \, .
\end{equation}
The main idea here is that the formulas in the precondition and
postcondition can \emph{relate} variables from different executions.
%
Cartesian Hoare logic is equipped with a proof system that allows one to prove the validity of CHL triples.
This proof system contains rules\footnote{We have changed the notation
  slightly compared to the original paper.} like
\begin{align}\label{chlRule:If}
    % & \prftree[l]{If}
    %   { % \prfStackPremises
    %     { \langle \Phi \land c \rangle (\texttt{B1; S}) \st R \langle \Psi
    %   \rangle } \qquad
    %     { \langle \Phi \land \neg c \rangle (\texttt{B2; S}) * R \langle \Psi \rangle }
    %   }
    %   { \langle \Phi \rangle (\texttt{if (c) {B1} {B2} ; S}) * R \langle \Psi \rangle }
    & \prftree[l]{If}
      { % \prfStackPremises
        { \chl{\Phi \land c}{(\texttt{B1; S}) \st R}{\Psi} } \qquad
        { \chl{\Phi \land \neg c}{(\texttt{B2; S}) \st R}{\Psi} }
      }
      { \chl{\Phi}{(\texttt{if (c) {B1} {B2} ; S}) \st R}{\Psi} }
\end{align}
that replicate standard Hoare-logic reasoning, and is sound and complete. 
However, what is more interesting, the proof system allows one to perform \emph{lockstep reasoning},
even for loops. This is achieved by means of the following rule (version for two executions):
\begin{align*}
  & \prftree[l]{Fusion}
    {
    \chl{I \land c_1 \land c_2}{\texttt{B1} \st \texttt{B2}}{I} \quad
    \chl{I \land \neg c_2}{\texttt{while (}c_1\texttt{) {B1}}}{\Psi} \quad
    \chl{I \land \neg c_1}{\texttt{while (}c_2\texttt{) {B2}}}{\Psi}    
  }
  { \chl{\Phi}{(\texttt{while (}c_1\texttt{) {B1}}) \st (\texttt{while (}c_2\texttt{) {B2}})} {\Psi}}
\end{align*}
%(which we present here in a simplified form, for Cartesian claims of arity 2 only).
Note that the invariant $I$, assumed by this rule, can relate variables from \emph{both} executions.
%
The rule breaks reasoning about a pair of loops into three cases: the case
where both loop conditions hold and two cases where one of the conditions
does not hold.  In the first case, both loops are executed ``in lockstep'',
performing one iteration each, and their execution must preserve the
invariant. In the remaining two cases, only one of the loops executes (in a
state satisfying the invariant and negation of the other loop condition),
resulting in a state satisfying the postcondition.


% This can be done by means of standard Hoare logic reasoning.

% For an example, consider the program
% \begin{equation}\label{eqn:CounterProgram}
% P(x,y) \equiv \texttt{while(}x\texttt{ > 0)\{ }y\texttt{++; }x\texttt{--;\}}
% \end{equation}
% and the property that $P$ is monotone with respect to the initial values of $x$ and $y$ and resulting value of $y$.
% This can be formalized as the CHL triple
% \begin{equation*}
% \langle x_1 \leq x_2 \land y_1 \leq y_2  \rangle (P(x_1, y_1) * P(x_2, y_2)) \langle y_1 \leq y_2 \rangle
% \end{equation*}
% Intuitively, this hyperproperty holds because we can synchronize the two executions until the point when the first one terminates;
% then, the second execution may continue for a while, making the difference betwen $y_2$ and $y_1$ even greater.
% Formally, we can apply the Fusion rule, with the precondition being also the relational invariant.
% This results in three subgoals:
% \begin{equation*}
%     \begin{aligned}
%         & \langle x_1 \leq x_2 \land y_1 \leq y_2 \land x_1 > 0 \land x_2 > 0  \rangle\ ( (y_1\texttt{++} ; x_1\texttt{--}); * (y_2\texttt{++} ; x_2\texttt{--}))\ \langle x_1 \leq x_2 \land y_1 \leq y_2 \rangle \\
%         & \{ x_1 \leq x_2 \land y_1 \leq y_2 \land \neg (x_1 > 0) \}\ P(x_2, y_2)\ \{ y_1 \leq y_2 \} \\
%         & \{ x_1 \leq x_2 \land y_1 \leq y_2 \land \neg (x_2 > 0) \}\ P(x_1, y_1)\ \{ y_1 \leq y_2 \} \\
%     \end{aligned}
% \end{equation*}
% The first one requires one to show that the body of the loop preserves the invariant,
% the second (third) represent the cases when the first (second) execution terminated.
% To prove the second subgoal, one needs to find a (non-relational) invariant of the (single) loop;
% the third subgoal is trivial, as its precondition implies the negation of the loop condition.

This lockstep reasoning is a powerful tool because the required invariants (relating
different executions) are often very simple. For example, consider the
program $P(x,y)$ and the formula (\ref{eq:mono_formula}) above.
% If one chooses
%the invariant to be the same as the precondition (i.e. $I \equiv x_1 \leq x_2 \land y_1 \leq y_2$),
%the precondition of the second premise becomes
%$\langle x_1 \leq x_2 \land y_1 \leq y_2 \land \neg (x_2 > 0) \rangle$, which implies
%$x_1 \leq 0$ and therefore the loop condition in $P(x_1, y_1)$ is not
%satisfied.
In this case it is enough to choose the invariant to be the same as the precondition (i.e. $I \equiv x_1 \leq x_2 \land y_1 \leq y_2$).
To prove the above example without lockstep reasoning, one must find (non-relational) loop invariants
strong enough to summarize the whole loop.

Unfortunately, lockstep reasoning rules become more complicated as one adds other features into the language
-- for example, the \texttt{break} statement (as done in \cite{SousaD16}).
It is not immediately obvious how to extend this approach to handle, e.g., recursion, \texttt{continue}, or \texttt{goto}.
We also observe that a single language feature (\texttt{while} loops) needed to be considered five times
in order for CHL to support it soundly: the semantics of \texttt{while} is present in the operational semantics of
the target language, in the Hoare logic for that language, in the Cartesian Hoare logic for that language,
and in the proofs of soundness for both of the logics.

This paper aims to make the above ideas available for any deterministic language.
Therefore, we review some tools from recent literature
on language-parametric program verification in the following subsections.

%\subsection{($\mu$-free) Matching Logic}
\subsection{Matching Logic}

Before introducing reachability logic, we must first talk about matching
logic, on top of which reachability logic is built. We work with the variant of matching logic described in
\cite{StefanescuCMMSR19, RosuSCM13lics}. (There are other variants of matching
logic, e.g. \cite{MmL, MLexplained}, which are of no particular interest for this paper.)


% This particular variant of matching logic is used for reasoning about static properties of program configurations.
% There exist newer and more expressive variants of matching logic (\cite{MmL, MLexplained});
% we used the older variant in order to be compatible with the literature on reachability logic which uses this variant.

% Matching logic \emph{formula} (commonly known as a \emph{pattern}) is a
% first-order logic (FOL) formula which additionally allows terms (with variables)
% over some signature $\Sigma$ as nullary predicates.
% A typical example of a matching logic formula is $\varphi_{\mathit{example}}$,
% defined as

% \begin{equation}\label{eqn:exampleMLPattern}
% \texttt{<k>x--<k><st>x} \texttt{|->} X\texttt{</st>} \land (X \texttt{ >Int } 1 = \mathit{true})
% \end{equation}

% which, when interpreted in a model of a particular programming language,
% denotes the set of program configurations in which the code \texttt{x--} is to be executed
% and in which the program variable $\texttt{x}$ has a value $X$ that is greater than $1$.
% In this example, the part
% \begin{equation*}
%     \texttt{<k>x--<k><st> x} \texttt{|->} X\texttt{ </st>}
% \end{equation*}
% is a nullary term used as a predicate (term-as-predicate), with $X$ being the only free FOL variable.
% Here $\texttt{x}$ is not a FOL variable, but a constant symbol from the signature of the programming language.
% The subterm $\texttt{<st>x} \texttt{ |-> } X\texttt{</st>}$ says that the program variable $\texttt{x}$
% has the value $X$, and the $X \texttt{ >Int } 1 = \mathit{true}$ part then says that the realization
% of the function symbol $\_ \texttt{ >Int } \_$ returns the boolean value $\mathit{true}$ when given $X$ and $1$
% as arguments.

%ALTERNATIVE NOTATION

A matching logic \emph{formula} (commonly known as a \emph{pattern}) is a
first-order logic (FOL) formula which additionally allows terms (with variables)
over some signature $\Sigma$ as nullary predicates.
A typical example of a matching logic formula is $\varphi_{\mathit{example}}$,
defined as\footnote{In the syntax of the \K{} framework this formula would look more like
$\texttt{<k>x--<k><st>x |-> X</st> } \land \texttt{ (X >Int  1 = true)}$.}


\begin{equation}\label{eqn:exampleMLPattern}
    \varphi_{\mathit{example}} \equiv\quad \tap{x--;}{\texttt{x}\mapsto X}  \land\ (X >_\text{Int} 1 = \mathit{true})
\end{equation}


which, when interpreted in a model of a particular programming language,
denotes the set of program configurations in which ``\texttt{x--;}'' is the
code to be executed next, and the program variable $\texttt{x}$ has a value $X$
that is greater than $1$.  In this example, the subformula
$\tap{x--;}{\mathtt{x}\mapsto X}$ is a nullary term used as a predicate
(term-as-predicate), with $X$ being the only free FOL variable.  ($\texttt{x}$
is not a FOL variable but a constant symbol from the signature of the
programming language.)  The subterm $\texttt{x}\mapsto X$ states that the
program variable $\texttt{x}$ has value $X$, and the
$X >_\text{Int} 1 = \mathit{true}$ part then says that the realization of the
function symbol ``$>_\text{Int}$'' returns the boolean value $\mathit{true}$
when given $X$ and $1$ as arguments.

The satisfaction relation $(M, \gamma, \rho) \vDash \varphi$ for a model $M$, a model element $\gamma \in M$,
an $M$-valuation $\rho$, and a pattern $\varphi$, is defined inductively on the structure of $\varphi$.
The definition is as in FOL; the main difference is the semantics of
terms-as-predicates, which is given as
\begin{equation*}
    (M, \gamma, \rho) \vDash t \iff \gamma = \rho(t) \text{ if t is a term}
\end{equation*}
(where $\rho(t)$ is the homomorphic extension of $\rho$ applied to the term $t$).
For example, we might have a matching logic model $M$ containing (concrete) program configurations
of a particular programming language.
One such configuration might be:
\begin{equation*}
  \gamma_{\mathit{example}} \equiv\quad \tap{x--;}{\mathtt{x}\mapsto 3}
    % \texttt{<k> x--; <k><st> x} \texttt{ |-> } 3\texttt{ </st>} \, .
\end{equation*}
Then, we have that $(M, \gamma_{\mathit{example}}, \rho) \vDash \varphi_{\mathit{example}}$
for any valuation $\rho$ satisfying $\rho(X) = 3$, and we say that
$\varphi_{\mathit{example}}$ \emph{matches} $\gamma_{\mathit{example}}$ in $\rho$.


A pattern $\varphi$ is \emph{valid in $M$}, written $M \vDash \varphi$, iff $(M, \gamma, \rho) \vDash \varphi$
for every $\gamma$ and $\rho$.
We observe that the validity of a structureless pattern (a pattern without terms-as-predicates) does not depend on the selected model element.
Also, the validity of any pattern does not depend on those variables the pattern does not mention.
A more formal treatment of matching logic is to be found in \Cref{app:MLandRL}.


\subsection{One-path Reachability Logic}
Reachability logic \cite{RosuS12oopsla, StefanescuCMMSR19} (RL) is a formalism for
both a) defining formal semantics of programming languages,
and b) specifying and reasoning about partial correctness properties
of programs in those languages.
On the formal semantics side, a programming language is modeled as a \emph{reachability system}
$\mathcal{S} = (\mathcal{T}, S)$, where $\mathcal{T}$ is a $\Sigma$-algebra
and $S$ is a set of \emph{reachability rules} of the shape $\varphi \Rightarrow^\exists \varphi^\prime$,
where $\varphi$ and $\varphi^\prime$ are \emph{matching logic} patterns over $\Sigma$
describing sets of \emph{source} and \emph{target} program configurations.

Each reachability system naturally induces a \emph{transition system}
$(\Tcfg , \Rightarrow_{\mathcal{S}})$, whose states are program configurations
and transitions $\Rightarrow_{\mathcal{S}}$ are defined as follows: for
$\gamma, \gamma^\prime \in \Tcfg$ we have
$\gamma \Rightarrow_{\mathcal{S}} \gamma^\prime$ iff there is some rule
$\varphi \Rightarrow^\exists \varphi^\prime \in S$ and some valuation
$\rho : \Var \to \mathcal{T}$ such that $(\gamma, \rho) \vDash \varphi$ and
$(\gamma^\prime , \rho) \vDash \varphi^\prime$.

As an example, consider the following reachability rule

\begin{equation}\label{eqn:ruleIfTrue}
    \tap{if ($true$) then $P_1$ else $P_2$}{S} \ \Rightarrow^{\exists}\ \tap{$P_1$}{S}
\end{equation}

saying that the \texttt{if} construct of the particular language takes the first branch ($P_1$)
whenever the condition is $\mathit{true}$. (Typically, there would be additional rules
governing the evaluation of the condition.)
%
This rule induces (among others) the transition
\begin{equation}\label{eqn:ruleIfTrue}
  \tap{if ($true$) then x++ else x--}{\mathtt{x}\mapsto 3}\
  \Rightarrow_{\mathcal{S}}\  \tap{x++}{\mathtt{x}\mapsto 3} \,.
\end{equation}



% Typically, \emph{program configurations} contain some program (or a fragment of it) that is to be executed,
% together with a state of the program.
% For example, one can have a rule
% \begin{equation}\label{eqn:ruleIfTrue}
%     \begin{aligned}
%     \texttt{<k>if (} \mathit{true} \texttt{) }P_1\texttt{ else } P_2 \texttt{</k><st>} S \texttt{</st>} 
%     \ \Rightarrow^{\exists}\ \texttt{<k>}P_1 \texttt{</k><st>} S \texttt{</st>}
%     \end{aligned}
% \end{equation}


% \begin{equation}\label{eqn:ruleIfTrue}
%     \begin{aligned}
%     & \texttt{<k> if (} \mathit{true} \texttt{) }P_1\texttt{ else } P_2 \texttt{</k><st>} S \texttt{</st>} \\
%     & \Rightarrow \texttt{<k> }P_1 \texttt{</k><st>} S \texttt{</st>}
%     \end{aligned}
% \end{equation}
% saying that the \texttt{if} construct of the particular language takes the first branch ($P_1$)
% whenever the condition is $\mathit{true}$.
% (Typically, there would be additional rules governing evaluation of the condition.)

% The meaning of reachability rules is the following.
% A reachability system $\mathcal{S} = (\mathcal{T}, S)$ (together with a $\Sigma$-sort $\mathit{Cfg}$)
% induces
% a \emph{transition system}
% $(\Tcfg , \Rightarrow_{\mathcal{S}})$,
% where $\gamma \Rightarrow_{\mathcal{S}} \gamma^\prime$
% for $\gamma, \gamma^\prime \in \Tcfg$
% iff there is some rule $\varphi \Rightarrow^\exists \varphi^\prime \in S$
% and some valuation $\rho : \Var \to \mathcal{T}$ with $(\gamma, \rho) \vDash \varphi$
% and $(\gamma^\prime , \rho) \vDash \varphi^\prime$.
% The intuition is that when taking a transition in the resulting transition system,
% some rule $\varphi \Rightarrow^\exists \varphi^\prime \in S$ is selected,
% then the current configuration is pattern-matched against the rule's left-side pattern $\varphi$,
% resulting in a valuation $\rho$ which is then used to instantiate the right-side $\varphi^\prime$ of the rule,
% forming a new configuration.
% For example, the rule in \Cref{eqn:ruleIfTrue} induces (among others) the transition
% \begin{equation}\label{eqn:ruleIfTrue}
%     \begin{aligned}
%     \texttt{<k>if (} \mathit{true} \texttt{) x++ else x--</k><st>x} \texttt{|->} 3\texttt{</st>}
%     \ \Rightarrow_{\mathcal{S}}\  \texttt{<k>x++</k><st>x} \texttt{|->} 3\texttt{</st>} \, .
%     \end{aligned}
% \end{equation}

% \begin{equation}\label{eqn:ruleIfTrue}
%     \begin{aligned}
%     & \texttt{<k> if (} \mathit{true} \texttt{) x++; else x--; </k><st>x} \texttt{ |-> } 3\texttt{</st>} \\
%     & \Rightarrow_{\mathcal{S}} \texttt{<k> x++; </k><st>x} \texttt{ |-> } 3\texttt{</st>} \, .
%     \end{aligned}
% \end{equation}

On the \emph{partial correctness} side, RL reuses the concept of reachability rules.
For example, one can specify that the program \texttt{while(x > 0) do x--;}
can, if it terminates at all, reach a configuration
where the program variable \texttt{x} has a non-positive value
by means of the following reachability rule
\begin{equation*}
  \tap{while (x>0) do x--;}{\mathtt{x}\mapsto V}
  \ \Rightarrow^\exists\  \exists V^\prime.\, \tap{$\cdot$}{\mathtt{x}\mapsto V'} \land (V^\prime \leq_\text{Int} 0 = \mathit{true})
  \end{equation*}
% \begin{equation*}
%     \begin{aligned}
%         & \texttt{<k>while( x > 0 ) x--</k><st>x|->} V \texttt{</st>} \\
%         & \Rightarrow^\exists \exists V^\prime.\, \texttt{<k> . </k> x |-> } V^\prime \texttt{</st>} \land (V^\prime \texttt{ <=Int } 0 = \mathit{true})
%     \end{aligned}
%   \end{equation*}
  
Assuming the language is deterministic, this is equivalent to saying that if the program terminates,
the resulting configuration will have a non-positive value of \texttt{x}.
Formally, a rule of the shape $\varphi \Rightarrow^\exists \varphi^\prime$
is \emph{satisfied}
in a reachability system $\mathcal{S} = (\mathcal{T}, S)$,
written $\mathcal{S} \vDash_\RL \varphi \Rightarrow^\exists \varphi^\prime$,
iff for every $\gamma \in \Tcfg$
such that $\gamma$ terminates in $(\Tcfg, \Rightarrow_{\mathcal{S}})$
and for any valuation $\rho : \Var \to \mathcal{T}$
such that $(\gamma, \rho) \vDash \varphi$,
there exists some $\gamma^\prime \in \Tcfg$
such that
$\gamma \Rightarrow^{*}_{\mathcal{S}} \gamma^\prime$
and $(\gamma^\prime, \rho) \vDash \varphi^\prime$.


Reachability logic is equipped with a proof system that derives sequents of the shape
$\mathcal{A}, C \vdash_\RL \varphi \Rightarrow^\exists \varphi^\prime$ (where $\mathcal{A}$ is a
reachability system and $C$ is introduced below). The proof system is sound and complete: an RL claim is satisfied in $\mathcal{S}$
iff $\mathcal{S}, \emptyset \vdash_\RL \varphi \Rightarrow^\exists \varphi^\prime$.
The set $C$, initially empty, contains so-called \emph{circularities},
which are claims postulated to hold but not justified yet.
Circularities, which correspond to the notion of \emph{loop invariants} of Hoare logic,
enable one to reason about repetitive behavior of programs.
The proof system contains a rule
\begin{align*}
    & \prftree[l]{Circularity}
      { \mathcal{A}, C \cup \{ \varphi\Rightarrow^\exists \varphi^\prime \} \vdash_\RL \varphi \Rightarrow^\exists \varphi^\prime }
      { \mathcal{A}, C \vdash_\RL \varphi \Rightarrow^\exists \varphi^\prime }
\end{align*}
which adds the current claim to the set of circularities.  When progress is
made (by means of other rules, essentially performing symbolic execution),
the claim is moved from the set of circularities to $\mathcal{A}$ (using the
\emph{Transitivity} rule -- see Appendix~\ref{app:crlsoundness}) and can be
reused, similarly to the way one assumes a loop invariant in order to prove it
again.  We refer the interested reader to~\cite{RosuS12oopsla} for more
details.


%For illustration purposes, we show one rule of the RL proof system:
%\begin{align*}
%    & \prftree[l]{Case Analysis}
%      %{ \prfStackPremises
%        { A, C \vdash_\RL \varphi_1 \Rightarrow^\exists \varphi }
%        { A, C \vdash_\RL \varphi_2 \Rightarrow^\exists \varphi }
%      %}
%      { A, C \vdash_\RL \varphi_1 \lor \varphi_2 \Rightarrow^\exists \varphi }
%\end{align*}


\begin{remark}\label{rem:noEmptySteps}
  We work only with $\epsilon$-free reachability systems.
  A reachability system $(\mathcal{T}, S)$ is \emph{$\epsilon$-free}
  iff for any two configurations $\sigma, \sigma^\prime \in \mathcal{T}_{\mathit{Cfg}}$, if
  $\sigma \Rightarrow_{\mathcal{S}} \sigma^\prime$, then $\sigma \not = \sigma^\prime$.
  (We are not aware of any practical reachability system that would use these $\epsilon$ steps.)
  \end{remark}

\begin{remark}\label{rem:shapeOfReachabilityRules}
  Following the original reachability logic literature (\cite{RosuS12oopsla,StefanescuCMMSR19}),
  we restrict the class of reachability systems we work with to those whose reachability rules
have the shape
\begin{equation*}
    \phi \land P \Rightarrow^\exists \phi^\prime \land P^\prime
\end{equation*}
where $\phi,\phi^\prime$ are terms-as-predicates, and $P,P^\prime$ contain no terms-as-predicate.
  As argued in these papers, such rules can support various styles of operational semantics,
  including evaluation contexts \cite{PLTRedex}, the chemical abstract machine \cite{CHAM}, and \K{} \cite{KVision}.
  We thus support all the $\epsilon$-free reachability systems supported by reachability logic.
\end{remark}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
